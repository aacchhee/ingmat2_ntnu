# Poissonligningen

## 1. Poissonligningen

La oss begynne med ligningen i en dimensjon, dvs

$$
u_{xx} = f(x)
$$

Vi kan løse ligningen ved å integrere to ganger.

### Eksempel

Hvis $f(x)=0$ har vi 
$$
u_x = \int f(x) dx = A\text{ og }u_{xx} = \int u_x dx = Ax + B,
$$ 
hvor konstantene $A$ og $B$ bestemmes ut fra randbetingelsene.

Ting blir fort mer komplisert i flere dimensjoner. 

### Randbetingelser

Ligningen 

$$
\bigtriangledown^2 u(\vec{x}) = f(\vec{x}), \quad \vec{x}\in \Omega
$$ 

kommer typisk med randbetingelser:

1. dirichletbetingelser

$$u(\vec{x}) = g(\vec{x}), \quad \vec{x}\in \partial \Omega$$

hvor $\partial\Omega$ er randen på området $\Omega$, og hvor vi oppgir løsningen på randen.

2. neumannbetingelser

$$ \frac{\partial u}{\partial \vec{n}}(\vec{x}) = g(\vec{x}), \quad \vec{x}\in \partial \Omega$$

Hvor $\vec{n}$ er normalvektoren på randen. Vi oppgir altså retningsderiverte til $u$ i retning ut av området $\Omega$.

Det er mulig å kombinere de to, enten ved å oppgi dirichletbetingelser på noen deler av randen og neumannbetingelser på andre, eller ved å si at summen av $u$ og $\frac{\partial u}{\partial \vec{n}}$ er lik en oppgitt funksjon. Sistnevnte kalles for en *robinbetingelse*, men vi skal ikke se på denne muligheten, selv om den ikke skaper utfordringer.

### Løsninger (ikke pensum)

Er geometrien pen nok kan vi fortsatt skrive løsningen som et integral. For eksempel ligningen på enhetsdisken:

$$
u_{xx} + u_{yy} = f(x,y), \quad x^2 + y^2 < 1, \qquad u(x,y)=0, \quad x^2+ y^2 = 1
$$

har følgende løsning:

$$
u(\vec{x}) = \frac{1}{2\pi}\int_{||\vec{y}||\leq 1} \frac{f(\vec{y})d\vec{y}}{\log||\vec{x}-\vec{y}|| -\log||\frac{\vec{x}}{||\vec{x}||^2}-\vec{y}||}
$$

Lekkert! Vi har bare noen få problemer:

1. Integralet er ikke så lett å løse.
2. Vi må finne et nytt integral hvis vi endrer geometrien av randbetingelsene.
3. For noen geometrier er det nesten like vanskelig å finne et slikt integral som å løse ligningen. 

### Eksempel:

Det kan vises at ligningen

$$
u_{xx}(x,y) + u_{yy}(x,y) = 0, \quad 0<x<1,\;\; 0<y<1
$$

med randbetingelser $u(x,0)=u(0,y)=u(1,y)=0$, $u(x,1)=\sin(\pi x)$, har løsning

$$
u(x,y) = \frac{\sin(\pi x)\sinh(\pi y)}{\sinh(\pi)}
$$

Her kan geometrien fortsatt skape vanskeligheter, men i mindre grad.

## 2. Numerisk metode: 1d randverdiproblem

La oss nå betrakte den ordinære differensialligningen

$$
u_{xx} + \omega^2 u = f(x), \quad u(0) = a,\;\; u(1) = b.
$$

Det blir det samme som en poissonligning i 1 dimensjon hvis vi har $\omega=0$.

Vi har lært i PNS/matte 1 at vi kan løse ligningen ved å skrive den om til en $2\times 2$ førsteordensligning. Men det blir litt vrient, da vi ender opp med randbetingelser på begge sider, så det er ikke hva vi gjør her.

### Utregning av $u_{xx}$

Strategien vi bruker her er å benytte Taylors teorem til å skrive:

$$
u_{xx} \approx \frac{1}{h^2} (u(x+h) - 2u(x) + u(x-h)) 
$$

Merk at formelen kun gjelder for $0<x<1$, og ikke på randen der $x=0$ eller $x=1$. 
Vi skal løse problemet numerisk ved å diskretisere og finne verdiene $u_i$ for $i=1,\cdots,m$. I tillegg kommer randbetingelsene $u_0=a$ og $u_{m+1}=b$.

Konsekvensen av dette blir at den andrederiverte kan regnes ut gjennom den lineære avblidningen $L$:

$$
L: u_n \mapsto \frac{u_{n+1}-2u_n+u_{n-1}}{h^2}
$$

for $n=1,\cdots, m$ (vi har også randverdiene).  Som lineær avbildning kan den beskrives med en $m\times m$-matrise, lik

$$
L = \frac{1}{h^2}
\begin{pmatrix}
-2 & 1 & 0  & \ldots & 0 & 0\\
1 & -2 & 1  & \ldots & 0 & 0\\
0 & 1 & -2  & \ldots & 0 & 0\\
\vdots & \vdots & \vdots &  & \vdots & \vdots \\
0 & 0 & 0 & \ldots  & -2 & 1 \\
0 & 0 & 0 & \ldots  & 1 & -2
\end{pmatrix}
$$

Nok en gang er det litt uklart hva som skjer ved randen. Vi skal se på det litt lenger ned i teksten, men først viser vi hvordan vi lager matrisen $L$
i Python.

### a) Programmering 1: en hurtigløsning

Vi lager matrisen $L$. Det viser seg å være forbausende lett!


```{pyodide-python}
import numpy as np
import matplotlib.pyplot as plt

plt.close("all")

# ------------------------------------------------------------
# Diskretisering av andrederivert (1D Laplace-operator)
# ------------------------------------------------------------
# Vi ser på intervallet [0, 1] og deler det inn i like store steg.
# Endepunktene x = 0 og x = 1 er randpunkter.
# De m indre punktene brukes som ukjente i det lineære systemet.
# ------------------------------------------------------------

m = 4                              # antall indre punkter
x = np.linspace(0, 1, m + 2)       # inkluderer randpunktene
h = x[1] - x[0]                    # steglengde i rom

print("Romgitter x:")
print(x)
print("Steglengde h =", h)

# ------------------------------------------------------------
# Matrise for -u'' ≈ (u_{i-1} - 2u_i + u_{i+1}) / h^2
#
# Dette gir en tridiagonal matrise:
#   -2 på hoveddiagonalen
#    1 på øvre og nedre bidiagonal
#
# Matrisen har størrelse m x m, siden vi kun har m indre punkter.
# ------------------------------------------------------------

L = (1 / h**2) * (
    np.diag((m - 1) * [1], -1) +
    np.diag(m * [-2], 0) +
    np.diag((m - 1) * [1], 1)
)

print("\nDiskret Laplace-matrise L:")
print(L)

# ------------------------------------------------------------
# Enkel visualisering av romgitteret
# ------------------------------------------------------------
plt.figure(figsize=(6, 2.5))
plt.plot(x, np.zeros_like(x), "o", markersize=6)

# Marker indre punkter og randpunkter forskjellig
plt.plot(x[1:-1], np.zeros(m), "o", label="indre punkter")
plt.plot([x[0], x[-1]], [0, 0], "s", label="randpunkter")

plt.title("Romgitter på [0, 1]")
plt.xlabel("x")
plt.yticks([])
plt.legend()
plt.show()
```

### b) Programmering 2: et alternativ

Vi kunne imidlertid også ha satt opp matrisen med en for-løkke. Å bygge matrisen med løkke gjør det tydelig hvordan hver indre gridverdi kobles til sine nærmeste naboer.
Dette er nyttig når vi senere generaliserer til variable koeffisienter eller høyere dimensjoner.


```{pyodide-python}
import numpy as np
import matplotlib.pyplot as plt

plt.close("all")

# ------------------------------------------------------------
# Bygging av Laplace-matrisen med løkke (for hånd)
# ------------------------------------------------------------
# Vi bruker samme oppsett som tidligere:
#  - m indre punkter
#  - steglengde h
# Målet er å konstruere den tridiagonale matrisen
# som representerer den andrederiverte.
# ------------------------------------------------------------

# Initialiserer matrisen med nuller
L_for = np.zeros((m, m))

# Løkke over radene
# For i = 0, 1, ..., m-2 fyller vi:
#   - hoveddiagonalen (i,i)
#   - øvre bidiagonal (i,i+1)
#   - nedre bidiagonal (i+1,i)
for i in range(m - 1):
    L_for[i, i]     = -2
    L_for[i, i + 1] =  1
    L_for[i + 1, i] =  1

# Siste diagonalelement (nederst til høyre)
# Dette blir ikke satt i løkka over
L_for[-1, -1] = -2

# Skalerer med 1/h^2 (kommer fra sentraldifferansen)
L_for = L_for / h**2

print("Laplace-matrise bygget med løkke:")
print(L_for)

# ------------------------------------------------------------
# Visualisering av romgitteret (samme som før, for sammenheng)
# ------------------------------------------------------------
plt.figure(figsize=(6, 2.5))
plt.plot(x, np.zeros_like(x), "o", markersize=6)
plt.plot(x[1:-1], np.zeros(m), "o", label="indre punkter")
plt.plot([x[0], x[-1]], [0, 0], "s", label="randpunkter")

plt.title("Romgitter på [0, 1]")
plt.xlabel("x")
plt.yticks([])
plt.legend()
plt.show()
```

## 3. Randbetingelsene 1: Dirichlet

Nå ser vi på hvordan randbetingelsene påvirker det som skjer ved randen. Vi ser altså på ligningen 

$$
u_{xx} + \omega^2 u = f(x), \quad u(0) = a, \; \; u(1) = b.
$$

Vi ser på tilfellet hvor $f(x)=0$ først.  La $u_n = u(x_n)$. Vi må legge inn $u_0 = u(0) = a$ og $u_{m+1} = u(1) = b$. Legg merke til at den første ligningen egentlig burde ha vært

$$
\frac{u_0 - 2u_1 + u_2}{h^2} + \omega^2 u_1 = 0
$$

Men den første linjen til $(L + \omega^2)\vec{u}=L\vec{u} + \omega^2 \vec{u}$ er lik

$$
\frac{- 2u_1 + u_2}{h^2} + \omega^2 u_1 = 0
$$

Vi må altså flytte $u_0$ til den andre siden og får

$$
\frac{- 2u_1 + u_2}{h^2} + \omega^2 u_1 = \frac{u_0}{h^2} = -\frac{a}{h^2}
$$

Vi gjør det samme med den siste ligningen i $(L + \omega^2) \vec{u} = 0$. Vi ender da opp med

$$
(L + \omega^2) \vec{u} = \vec{F}, \quad
\vec{F} = \begin{pmatrix}
-\frac{a}{h^2} \\
0 \\
\vdots \\
0 \\
-\frac{b}{h^2}
\end{pmatrix}
$$

Hvis $f(x)$ ikke er $0$, må vi først beregne $\vec{F} = f(x)$. Vi legger en kommentar i koden under for å vise hvordan dette kan gjøre i praksis. Randbetingelsene påvirker ikke bare løsningen direkte, men også høyresiden i det lineære systemet.
Dette er grunnen til at de første og siste komponentene i $F$ må justeres.


```{pyodide-python}
import numpy as np
import matplotlib.pyplot as plt
import numpy.linalg as la

plt.close("all")

# ------------------------------------------------------------
# Stasjonært randverdiproblem
#
#   -u''(x) + ω^2 u(x) = f(x),    x ∈ (0,1)
#   u(0) = a,   u(1) = b
#
# Diskretisert med sentrale differanser.
# ------------------------------------------------------------

omega = 1.0        # parameter i ligningen
a = -1.0           # randverdi u(0)
b =  1.0           # randverdi u(1)

# ------------------------------------------------------------
# Ligningssystem:  A U = F
#
# L er Laplace-matrisen fra tidligere:
#   L ≈ -d^2/dx^2
#
# Derfor blir:
#   A = L + ω^2 I
# ------------------------------------------------------------
A = L + (omega**2) * np.eye(m)

# ------------------------------------------------------------
# Høyreside f(x)
# I dette eksemplet tar vi f(x) = 0
# ------------------------------------------------------------
F = np.zeros(m)

# ------------------------------------------------------------
# Bidrag fra randbetingelser
#
# Når vi bruker sentrale differanser, vil u_0 og u_{m+1}
# (randpunktene) dukke opp i ligningene for de indre punktene.
# Disse flyttes over til høyresiden.
# ------------------------------------------------------------
F[0]  -= a / h**2     # bidrag fra u(0) = a
F[-1] -= b / h**2    # bidrag fra u(1) = b

# ------------------------------------------------------------
# Løs det lineære systemet
# ------------------------------------------------------------
U = la.solve(A, F)

print("Løsning i de indre punktene:")
print(U)

# ------------------------------------------------------------
# Visualisering av løsningen
# ------------------------------------------------------------
# Vi setter sammen full løsning, inkludert randpunktene
u_full = np.zeros(m + 2)
u_full[0] = a
u_full[-1] = b
u_full[1:-1] = U

plt.figure(figsize=(6, 4))
plt.plot(x, u_full, "o-", label="Numerisk løsning")
plt.xlabel("x")
plt.ylabel("u(x)")
plt.title("Løsning av -u'' + ω²u = 0 med Dirichlet-randbetingelser")
plt.legend()
plt.show()
```

### Test

Så langt har vi bare prøvd små verdier for $m$ for å illustrere prosessen. Vi prøver nå med større verdier på ligningen 

$$
\frac{d^2 u}{dx^2} + \pi^2 u = 0, \quad u(0) = -1,\;\; u(1) = 1.
$$

Den generelle løsningen er   
$$
u = A\sin\pi x + B\cos\pi x,
$$

Vi har $u(0)=B$ og $u(1)=-B$, slik at den eksakte løsningen blir

$$
u = - \cos\pi x
$$

Vi løser dette numerisk.


```{pyodide-python}
import numpy as np
import matplotlib.pyplot as plt
import numpy.linalg as la

plt.close("all")

# ------------------------------------------------------------
# Vi løser randverdiproblemet
#
#   -u''(x) + ω^2 u(x) = 0,     x ∈ (0,1)
#   u(0) = a,   u(1) = b
#
# og sammenligner numerisk løsning med en analytisk løsning.
# ------------------------------------------------------------

omega = np.pi
a = -1.0
b =  1.0

# Flere punkter gir bedre nøyaktighet
m = 100                       # antall indre punkter
x = np.linspace(0, 1, m + 2)  # inkluderer randpunktene
h = x[1] - x[0]               # steglengde

# ------------------------------------------------------------
# Diskret operator:
# L ≈ -d^2/dx^2   (m x m-matrise for indre punkter)
# A = L + ω^2 I
# ------------------------------------------------------------
L = (1 / h**2) * (
    np.diag((m - 1) * [1], -1) +
    np.diag(m * [-2], 0) +
    np.diag((m - 1) * [1], 1)
)
A = L + (omega**2) * np.eye(m)

# ------------------------------------------------------------
# Høyreside f(x) = 0 (her)
# Randbetingelser flyttes inn i høyresiden ved første og siste ligning
# ------------------------------------------------------------
F = np.zeros(m)
F[0]  -= a / h**2
F[-1] -= b / h**2

# Numerisk løsning i indre punkter
U_num = la.solve(A, F)

# ------------------------------------------------------------
# Analytisk løsning
#
# Når f(x)=0, har vi:
#   -u'' + ω^2 u = 0  =>  u'' = ω^2 u
# som gir løsninger av typen u = C e^{ωx} + D e^{-ωx}
#
# I dette eksempelet bruker vi en kjent lukket form som passer randdataene.
# (Her er den gitt som: u(x) = -cos(ωx) i de indre punktene.)
# Merk: Denne formen oppfyller u(0) = -1. For at u(1)=1 skal stemme,
# må ω velges slik at cos(ω)= -1, dvs. ω = (2k+1)π. Med ω=π fungerer det.
# ------------------------------------------------------------
U_exact = -np.cos(omega * x[1:-1])

# ------------------------------------------------------------
# Plot: numerisk vs analytisk
# Hvis alt stemmer, ligger kurvene praktisk talt oppå hverandre.
# ------------------------------------------------------------
plt.figure(figsize=(6, 4))
plt.plot(x[1:-1], U_num, label="numerisk")
plt.plot(x[1:-1], U_exact, "--", label="analytisk")

plt.xlabel("x")
plt.ylabel("u(x)")
plt.title(r"Sammenligning: numerisk vs analytisk, $\omega=\pi$")
plt.legend()

# Den stiplete linjen er analytisk.
# Hvis alt gikk bra ser du (nesten) bare én kurve,
# fordi løsningene følger hverandre tett.
plt.show()
```
